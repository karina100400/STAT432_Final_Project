---
title: "STAT 432 Project"
output: html_document
date: "2025-04-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#loading libraryies
library(tidyverse)
library(car)
library(caret)
library(class)
library(pROC)

#setting seed
set.seed(7)

uiuc_extended <- c(
  "caucasian" = "#E84A27",
  "black or african american" = "#7393B3",
  "asian" = "#FFBD00",   # optional: Illinois yellow for contrast
  "american indian or alaska native" = "#5F6A72"  # muted grey-blue
)

```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.


```{r loading data}
#preprocessed data
glioma <- read_csv("TCGA_InfoWithGrade.csv")
glioma_labels <- read_csv("TCGA_GBM_LGG_Mutations_all.csv")

#replacing white race with caucasian
glioma_labels <- glioma_labels %>%
  mutate(Race = ifelse(Race == "white", "caucasian", Race))

head(glioma)
head(glioma_labels)
```
```{r processing}
#define a function to replace '--' and 'not reported' with NA
replace_missing <- function(x) {
  x[x == "--" | tolower(x) == "not reported"] <- NA
  return(x)
}

#apply the function to relevant columns
glioma_labels$Gender <- replace_missing(glioma_labels$Gender)
glioma_labels$Race <- replace_missing(glioma_labels$Race)
glioma_labels$Age_at_diagnosis <- replace_missing(glioma_labels$Age_at_diagnosis)

glioma_labels <- glioma_labels %>%
  mutate(
    #extract number of years and days (age) of patient
    years = as.numeric(str_extract(Age_at_diagnosis, "\\d+(?=\\s*years)")),
    days = as.numeric(str_extract(Age_at_diagnosis, "\\d+(?=\\s*days)")),
    
    #replace NA with 0 if one of the parts is missing
    years = ifelse(is.na(years), 0, years),
    days = ifelse(is.na(days), 0, days),
    
    #convert to decimal years
    Age_at_diagnosis = years + (days / 365)
  ) %>% 
  select(-years, -days)
```

```{r missing values}
#checking missing values

#impute Gender with mode
glioma_labels$Gender[is.na(glioma_labels$Gender)] <- names(sort(table(glioma_labels$Gender), decreasing = TRUE))[1]

#impute Race with mode
glioma_labels$Race[is.na(glioma_labels$Race)] <- names(sort(table(glioma_labels$Race), decreasing = TRUE))[1]

#convert Age_at_diagnosis to numeric
glioma_labels$Age_at_diagnosis <- as.numeric(glioma_labels$Age_at_diagnosis)

#impute Age_at_diagnosis with median
glioma_labels$Age_at_diagnosis[is.na(glioma_labels$Age_at_diagnosis)] <- median(glioma_labels$Age_at_diagnosis, na.rm = TRUE)

# Check for any remaining missing values
sum(is.na(glioma_labels$Gender))           
sum(is.na(glioma_labels$Race))             
sum(is.na(glioma_labels$Age_at_diagnosis)) 

```

```{r}
#processing to factorization and hotcoding

#hot coding mutation columns
mutation_cols <- colnames(glioma_labels)[8:27]

glioma_labels <- glioma_labels %>%
  mutate(across(all_of(mutation_cols),
                ~ ifelse(. == "MUTATED", 1,
                         ifelse(. == "NOT_MUTATED", 0, NA))),
         across(8:27, as.factor))

#turning hotcoded columns into factor cols
glioma_labels <- glioma_labels %>%
  select("Age_at_diagnosis", everything()) %>%
  mutate(across(2:24, as.factor))

head(glioma_labels)

```

```{r age/gender boxplot}
p <- ggplot(glioma_labels, mapping = aes(y = Age_at_diagnosis, x = Grade, 
                             fill = Gender)) +
  geom_boxplot() +
  scale_fill_manual(values = c("Male" = "#E84A27", "Female" = "#7393B3")) +
  labs(y = "Age at Diagnosis", title = "Diagnosis Type at Age & Gender Boxplot",
       fill = "Gender")  +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

p

#saving plot as png
ggsave("age_gender_diagnostics.png", plot = p, width = 6, height = 4, dpi = 300)
```



```{r race}
race_df <- glioma_labels
race_df$Race <- factor(glioma_labels$Race, levels = rev(levels(factor(glioma_labels$Race))))

race_plot <-  ggplot(race_df, aes(x = Race, fill = Race)) +
  geom_bar(position = 'dodge') + 
  labs(fill = "Race", y = "Count", title = "Proportion of Race within Patient Sample") +
  theme(axis.text.x = element_text(size = 6)) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  coord_flip() + 
  scale_fill_manual(values = uiuc_extended)

race_plot

#saving plot as png
ggsave("race_plot.png", plot = race_plot, width = 6, height = 2, dpi = 300)
```



```{r}
uiuc_org <- "#E84A27"
uiuc_blue <- "#4F6D94"
# Convert to long format
df_long <- glioma_labels %>%
  pivot_longer(cols = c(colnames(glioma_labels)[8:27]), 
               names_to = "Feature",
               values_to = "Value")

#grade across each Feature
grade_gene <- ggplot(df_long, aes(x = Value, fill = Grade)) +
  geom_bar(position = "stack") +
  facet_wrap(~ Feature, scales = "free_x") +
  labs(x = "Mutation Status (0 = Not Mutated, 1 = Mutated)", 
       y = "Count", 
       fill = "Grade",
       title = "Proportion of Classifications within Mutated Genes") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c('LGG' = uiuc_org, 'GBM' = uiuc_blue))

grade_gene

#saving plot as png
ggsave("grade_gene.png", plot = grade_gene, width = 6, height = 4, dpi = 300)
```



```{r multicollinearity}
model <- glm(Grade ~ ., data = glioma)

# Get VIF values
vif_values <- vif(model)

# Turn into a data frame for plotting
vif_df <- data.frame(
  Variable = names(vif_values),
  VIF = vif_values
)

vif_plot <- ggplot(vif_df, aes(x = reorder(Variable, VIF), y = VIF)) +
  geom_col(fill = uiuc_blue) +
  geom_hline(yintercept = 5, color = "red", linetype = "dashed") +  
  coord_flip() +
  labs(title = "VIF Values for Predictors", x = "Variables", y = "VIF") +
  theme_minimal()  +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        axis.text.y = element_text(size = 2))

vif_plot

#saving plot as png
ggsave("vif_plot.png", plot = vif_plot, width = 6, height = 2, dpi = 300)
```
```{r Splitting training and testing}
# set seed
set.seed(7)

#removing ID columns
glioma_Labels <- glioma_labels %>% 
  select(-Project, -Case_ID, -Primary_Diagnosis)

# number of rows in entire dataset
gliomaNumRows <- dim(glioma_Labels)[1]
gliomaTestNumRows <- gliomaNumRows*0.2

# separate dataset into train and test
test_idx <- sample(x = 1:gliomaNumRows, size = gliomaTestNumRows)
Glioma_train <- glioma_Labels[-test_idx,]
Glioma_test <- glioma_Labels[test_idx,]

#one-hot encoding
dummies <- dummyVars(Grade ~ ., data = glioma_Labels)

# apply transformation to train and test sets
X_train <- predict(dummies, newdata = Glioma_train)
X_test  <- predict(dummies, newdata = Glioma_test)

# extract labels
Y_train <- Glioma_train$Grade
Y_test  <- Glioma_test$Grade

```

##Finding optimal K for KNN

```{r KNN}
# parameters for cross-validation
resamplingMethod <- "cv"
numFolds <- 20
classificationMethod <- "knn"
performanceMetric <- "ROC"

# sequence of K values
K_seq <- data.frame(k = c(1, 5, 10, 20, 50, 100))

# setup the cross-validation options
knn_cv_train_control <- trainControl(method = resamplingMethod,
                                     number = numFolds,
                                     classProbs = TRUE,
                                     summaryFunction = twoClassSummary)

# train the model
knn_cv_train <- train(x = X_train,
                      y = Y_train,
                      method = classificationMethod,
                      metric = performanceMetric,
                      trControl = knn_cv_train_control,
                      tuneGrid = K_seq)

print(knn_cv_train)
```
### Fitting KNN model with optimal K
```{r KNN}
# best K
opt_K <- 10

knn_train <- knn(train = X_train,
                 test = X_test,
                 cl = Y_train,
                 k = opt_K, 
                 prob = TRUE)

### Extract probabilities (needed for AUC)
# Note: The 'prob' attribute gives the proportion of votes for the winning class
# For binary classification, we need probabilities for the positive class
knn_probs <- ifelse(
  knn_train == levels(Y_train)[2],  # Assuming 2nd level is the positive class
  attr(knn_train, "prob"),          # Probability of winning class
  1 - attr(knn_train, "prob")       # If predicted as negative, take 1 - prob
)

### Calculate AUC
roc_obj <- roc(response = Y_test, predictor = knn_probs)
auc_KNN <- auc(roc_obj)

### Print AUC
print(paste("AUC:", auc_KNN))

### Plot ROC curve (optional)
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_KNN, 3), ")"))
```
#### Calculating accuracy statistics
```{r KNN accuracy}
# prediction confusion matrix on the test dataset
KNNconfusionMat <- table(Predicted = knn_train, Actual = Y_test)
print(KNNconfusionMat)

# calculate test error
numCorrectPredictions <- sum(diag(KNNconfusionMat))
numPredictions <- sum(KNNconfusionMat)
acc_KNN <- 1- (numCorrectPredictions/numPredictions)
print(paste0("The test error is: ", acc_KNN))

#metrics
TP <- confusion_mat[1, 1]  # True Positives (Class 1 correctly predicted)
FN <- confusion_mat[1, 2]  # False Negatives (Class 1 predicted as Class 2)
FP <- confusion_mat[2, 1]  # False Positives (Class 2 predicted as Class 1)
TN <- confusion_mat[2, 2]  # True Negatives (Class 2 correctly predicted)


acc_KNN <- sum(diag(confusion_mat)) / sum(confusion_mat)
sens_KNN <- TP / (TP + FN) #TP / (TP + FN)
spec_KNN <- TN / (TN + FP) # TN / (TN + FP)
prec_KNN <- TP / (TP + FP) #TP / (TP + FP)
f1_score_KNN <- 2 * (precision * sensitivity) / (precision + sensitivity)

# Print results
print(paste("Accuracy:", round(acc_KNN, 4)))
print(paste("Sensitivity:", round(sens_KNN, 4)))
print(paste("Specificity:", round(spec_KNN, 4)))
print(paste("Precision:", round(prec_KNN, 4)))
print(paste("F1-Score:", round(f1_score_KNN, 4)))
```

###Logistic Regression

```{r Logistic Regression}

# Fit logistic regression (all predictors)
logistic_model <- glm(
  Grade ~ .,               
  data = Glioma_train,
  family = binomial(link = "logit")
)

# Model summary (check p-values)
summary(logistic_model)

#predict
pred_probs <- predict(logistic_model, newdata = Glioma_test, type = "response")

# Convert to class predictions (cutoff = 0.5)
pred_classes <- ifelse(pred_probs > 0.5, 1, 0)

# Confusion matrix
confusion_mat <- table(Predicted = pred_classes, Actual = Y_test)
print(confusion_mat)

#metrics
TP <- confusion_mat[1, 1]  # True Positives (Class 1 correctly predicted)
FN <- confusion_mat[1, 2]  # False Negatives (Class 1 predicted as Class 2)
FP <- confusion_mat[2, 1]  # False Positives (Class 2 predicted as Class 1)
TN <- confusion_mat[2, 2]  # True Negatives (Class 2 correctly predicted)


acc_LR <- sum(diag(confusion_mat)) / sum(confusion_mat)
sens_LR <- TP / (TP + FN) #TP / (TP + FN)
spec_LR <- TN / (TN + FP) # TN / (TN + FP)
prec_LR <- TP / (TP + FP) #TP / (TP + FP)
f1_score_LR <- 2 * (precision * sensitivity) / (precision + sensitivity)

# Print results
print(paste("Accuracy:", round(acc_LR, 4)))
print(paste("Sensitivity (Recall) for Class 1 (Positive):", round(sens_LR, 4)))
print(paste("Specificity for Class 2 (Negative):", round(spec_LR, 4)))
print(paste("Precision for Class 1 (Positive):", round(prec_LR, 4)))
print(paste("F1-Score:", round(f1_score_LR, 4)))

roc_obj <- roc(response = Y_test, predictor = pred_probs)
plot(roc_obj, main = "ROC Curve for Glioma Grade Prediction")
auc_LR <- auc(roc_obj)
cat("AUC:", round(auc_LR, 3))  # AUC > 0.7 indicates good discrimination

```


### Random Forest Classifier


```{r}
library(randomForest)
set.seed(7)
rf_control <- trainControl(method="cv", number = 10, search = "grid", classProbs = TRUE, summaryFunction = twoClassSummary)

tunegrid <- expand.grid(.mtry=c(1:6))
Glioma_rfc <- train(Grade~., data=Glioma_train, method="rf", metric="ROC", tuneGrid=tunegrid, trControl=rf_control)
```

```{r}
Glioma_rfc_pred <- predict(Glioma_rfc, newdata=Glioma_test, type="prob")
Glioma_rfc_predicted <- predict(Glioma_rfc, newdata=Glioma_test)



Glioma_rfc_1_conf_matrix <- confusionMatrix(Glioma_rfc_predicted,Glioma_test$Grade)
Glioma_rfc_1_conf_matrix

auc_RF <- auc(roc(Glioma_test$Grade, Glioma_rfc_pred[,"GBM"]))
print(auc_RF)
acc_RF <- 0.8488
spec_RF <- 0.8113
sens_RF <- 0.9091
prec_RF <- 0.75
```


### Gradient Boosting Model
```{r}

#gbm requires output class to be {0,1}
Glioma_train_boosting <- Glioma_train %>% 
  mutate(Grade = ifelse(Grade=="GBM",1,0))
```

```{r}
library(gbm)
set.seed(7)

#Trying different learning rates (0.1, 0.01, 0.001) and using cv to choose optimal ntrees

# Learning Rate 0.1
Glioma_GBM1 <- gbm(Grade ~., data=Glioma_train_boosting, distribution="bernoulli", n.trees=1000, interaction.depth = 3, shrinkage=0.1, cv.folds = 5)
#finding optimal number of trees
best_iter1 <- gbm.perf(Glioma_GBM1, method = "cv")
#getting class labels
Glioma_GBM1_pred <- predict(Glioma_GBM1, newdata = Glioma_test, n.trees = best_iter1, type="response")
#converting reponse variable back into string for conf matrix
Glioma_GBM1_predicted <- ifelse(Glioma_GBM1_pred > 0.5, 1, 0)
Glioma_GBM1_predicted <- ifelse(Glioma_GBM1_predicted == 1, "GBM", "LGG")

Glioma_GBM1_conf_matrix <- table(Predicted = Glioma_GBM1_predicted, Actual = Glioma_test$Grade)
Glioma_GBM1_conf_matrix

Glioma_GBM1_test_error <- 1-(sum(diag(Glioma_GBM1_conf_matrix))/sum(Glioma_GBM1_conf_matrix))
Glioma_GBM1_test_error

 
# auc_value <- auc(roc(Glioma_test$Grade, Glioma_GBM1_pred))
# print(auc_value)
```

```{r}
set.seed(7)
# Learning Rate 0.01
Glioma_GBM2 <- gbm(Grade ~., data=Glioma_train_boosting, distribution="bernoulli", n.trees=3000, interaction.depth = 3, shrinkage=0.01, cv.folds = 5)
best_iter2 <- gbm.perf(Glioma_GBM2, method = "cv")

Glioma_GBM2_pred <- predict(Glioma_GBM2, newdata = Glioma_test, n.trees = best_iter2, type="response")
Glioma_GBM2_predicted <- ifelse(Glioma_GBM2_pred > 0.5, 1, 0)
Glioma_GBM2_predicted <- ifelse(Glioma_GBM2_predicted == 1, "GBM", "LGG")

Glioma_GBM2_conf_matrix <- table(Predicted = Glioma_GBM2_predicted, Actual = Glioma_test$Grade)
Glioma_GBM2_conf_matrix

Glioma_GBM2_test_error <- 1-(sum(diag(Glioma_GBM2_conf_matrix))/sum(Glioma_GBM2_conf_matrix))
Glioma_GBM2_test_error

auc_GB <- auc(roc(Glioma_test$Grade, Glioma_GBM2_pred))
print(auc_GB)

acc_GB <- (sum(diag(Glioma_GBM2_conf_matrix))/sum(Glioma_GBM2_conf_matrix))
acc_GB
spec_GB <- Glioma_GBM2_conf_matrix[1,1] / (Glioma_GBM2_conf_matrix[1,1] + Glioma_GBM2_conf_matrix[2,1])
spec_GB
sens_GB <- Glioma_GBM2_conf_matrix[2,2] / (Glioma_GBM2_conf_matrix[2,2] + Glioma_GBM2_conf_matrix[1,2])
sens_GB
prec_GB <- Glioma_GBM2_conf_matrix[1,1] / (Glioma_GBM2_conf_matrix[1,1] + Glioma_GBM2_conf_matrix[1,2])
prec_GB
```

Glioma_GBM2 was our best gbm model 

### Adaboost

```{r}
set.seed(7)
# Learning Rate 0.01
Glioma_Ada <- gbm(Grade ~., data=Glioma_train_boosting, distribution="adaboost", n.trees=3000, interaction.depth = 3, shrinkage=0.01 ,cv.folds = 5)
best_iter_ada <- gbm.perf(Glioma_Ada, method = "cv")

Glioma_Ada_pred <- predict(Glioma_Ada, newdata = Glioma_test, n.trees = best_iter2, type="response")
Glioma_Ada_predicted <- ifelse(Glioma_Ada_pred > 0.5, 1, 0)
Glioma_Ada_predicted <- ifelse(Glioma_Ada_predicted == 1, "GBM", "LGG")

Glioma_Ada_conf_matrix <- table(Predicted = Glioma_Ada_predicted, Actual = Glioma_test$Grade)
Glioma_Ada_conf_matrix

Glioma_Ada_test_error <- 1-(sum(diag(Glioma_Ada_conf_matrix))/sum(Glioma_Ada_conf_matrix))
Glioma_Ada_test_error

auc_AB <- auc(roc(Glioma_test$Grade, Glioma_Ada_pred))
print(auc_AB)

acc_AB <- (sum(diag(Glioma_Ada_conf_matrix))/sum(Glioma_Ada_conf_matrix))
acc_AB
spec_AB <- Glioma_Ada_conf_matrix[1,1] / (Glioma_Ada_conf_matrix[1,1] + Glioma_Ada_conf_matrix[2,1])
spec_AB
sens_AB <- Glioma_Ada_conf_matrix[2,2] / (Glioma_Ada_conf_matrix[2,2] + Glioma_Ada_conf_matrix[1,2])
sens_AB
prec_AB <- Glioma_Ada_conf_matrix[1,1] / (Glioma_Ada_conf_matrix[1,1] + Glioma_Ada_conf_matrix[1,2])
prec_AB
```
Adaboost performed very similarly to GBM. Slightly higher test error but also higher AUC.


### SVM
```{r}
set.seed(7)
library(e1071)
tune_linear=tune(svm, Grade~., data=Glioma_train, kernel ="linear",
ranges=list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100), probability = TRUE)
)
summary(tune_linear)
```
```{r}
#Fitting SVM Model linear
Glioma_SVM_linear <- tune_linear$best.model

Glioma_SVM_linear_pred <- predict(Glioma_SVM_linear, Glioma_test, probability = TRUE) #returns labels directly
#getting probabilities to calculate AUC
Glioma_SVM_linear_probs <- attr(Glioma_SVM_linear_pred, "probabilities")



Glioma_SVM_linear_conf_matrix <- table(Predicted = Glioma_SVM_linear_pred, Actual = Glioma_test$Grade)
Glioma_SVM_linear_conf_matrix

Glioma_SVM_linear_test_error <- 1-(sum(diag(Glioma_SVM_linear_conf_matrix))/sum(Glioma_SVM_linear_conf_matrix))
Glioma_SVM_linear_test_error

auc_value <- auc(roc(Glioma_test$Grade, Glioma_SVM_linear_probs[,"GBM"]))
print(auc_value)
```


```{r}
set.seed(7)
tune_radial=tune(svm, Grade~., data=Glioma_train, kernel ="radial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100)), probability = TRUE
)
Glioma_SVM_radial <- tune_radial$best.model

Glioma_SVM_radial_pred <- predict(Glioma_SVM_radial, Glioma_test, probability = TRUE) #returns labels directly
Glioma_SVM_radial_probs <- attr(Glioma_SVM_radial_pred, "probabilities")

Glioma_SVM_radial_conf_matrix <- table(Predicted = Glioma_SVM_radial_pred, Actual = Glioma_test$Grade)
Glioma_SVM_radial_conf_matrix

Glioma_SVM_radial_test_error <- 1-(sum(diag(Glioma_SVM_radial_conf_matrix))/sum(Glioma_SVM_radial_conf_matrix))
Glioma_SVM_radial_test_error

auc_SVM <- auc(roc(Glioma_test$Grade, Glioma_SVM_radial_probs[,"GBM"]))
print(auc_SVM)



acc_SVM <- (sum(diag(Glioma_SVM_radial_conf_matrix))/sum(Glioma_SVM_radial_conf_matrix))
acc_SVM
spec_SVM <- Glioma_SVM_radial_conf_matrix[1,1] / (Glioma_SVM_radial_conf_matrix[1,1] + Glioma_SVM_radial_conf_matrix[2,1])
spec_SVM
sens_SVM <- Glioma_SVM_radial_conf_matrix[2,2] / (Glioma_SVM_radial_conf_matrix[2,2] + Glioma_SVM_radial_conf_matrix[1,2])
sens_SVM
prec_SVM <- Glioma_SVM_radial_conf_matrix[1,1] / (Glioma_SVM_radial_conf_matrix[1,1] + Glioma_SVM_radial_conf_matrix[1,2])
prec_SVM
```

```{r}
set.seed(7)
tune_poly=tune(svm, Grade~., data=Glioma_train, kernel ="polynomial",
ranges=list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100), degree=c(2,3)), probability = TRUE
)
Glioma_SVM_poly <- tune_poly$best.model

Glioma_SVM_poly_pred <- predict(Glioma_SVM_poly, Glioma_test, probability = TRUE) #returns labels directly
Glioma_SVM_poly_probs <- attr(Glioma_SVM_poly_pred, "probabilities")

Glioma_SVM_poly_conf_matrix <- table(Predicted = Glioma_SVM_poly_pred, Actual = Glioma_test$Grade)
Glioma_SVM_poly_conf_matrix

Glioma_SVM_poly_test_error <- 1-(sum(diag(Glioma_SVM_poly_conf_matrix))/sum(Glioma_SVM_poly_conf_matrix))
Glioma_SVM_poly_test_error

auc_value <- auc(roc(Glioma_test$Grade, Glioma_SVM_poly_probs[,"GBM"]))
print(auc_value)
```
All three SVM models performed similarly in terms of test error. The radial SVM model has the highest AUC among all our models.

#results table
```{r}
results_table <- data.frame(
  Model = c("KNN", "Logistic Regression", "Random Forest", 
            "Gradient Boosting", "AdaBoost", "SVM"),
  AUC = c(auc_KNN, auc_LR, auc_RF, auc_GB, auc_AB, auc_SVM),
  Accuracy = c(acc_KNN, acc_LR, acc_RF, acc_GB, acc_AB, acc_SVM),
  Sensitivity = c(sens_KNN, sens_LR, sens_RF, sens_GB, sens_AB, sens_SVM),
  Specificity = c(spec_KNN, spec_LR, spec_RF, spec_GB, spec_AB, spec_SVM),
  Precision = c(prec_KNN, prec_LR, prec_RF, prec_GB, prec_AB, prec_SVM),
  F1_Score = c(
    2 * (prec_KNN * sens_KNN) / (prec_KNN + sens_KNN),
    2 * (prec_LR * sens_LR) / (prec_LR + sens_LR),
    2 * (prec_RF * sens_RF) / (prec_RF + sens_RF),
    2 * (prec_GB * sens_GB) / (prec_GB + sens_GB),
    2 * (prec_AB * sens_AB) / (prec_AB + sens_AB),
    2 * (prec_SVM * sens_SVM) / (prec_SVM + sens_SVM)
  )
)

# Round all numeric columns to 4 decimal places
results_table[, -1] <- round(results_table[, -1], 4)

# Print the formatted table
print(results_table)

```

