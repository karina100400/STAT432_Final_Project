---
title: "STAT 432 Project"
output: html_document
date: "2025-04-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#loading libraryies
library(tidyverse)
library(car)
library(caret)
library(class)
library(pROC)

#setting seed
set.seed(7)

uiuc_extended <- c(
  "caucasian" = "#E84A27",
  "black or african american" = "#7393B3",
  "asian" = "#FFBD00",   # optional: Illinois yellow for contrast
  "american indian or alaska native" = "#5F6A72"  # muted grey-blue
)

```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.


```{r loading data}
#preprocessed data
glioma <- read_csv("TCGA_InfoWithGrade.csv")
glioma_labels <- read_csv("TCGA_GBM_LGG_Mutations_all.csv")

#replacing white race with caucasian
glioma_labels <- glioma_labels %>%
  mutate(Race = ifelse(Race == "white", "caucasian", Race))

head(glioma)
head(glioma_labels)
```
```{r processing}
#define a function to replace '--' and 'not reported' with NA
replace_missing <- function(x) {
  x[x == "--" | tolower(x) == "not reported"] <- NA
  return(x)
}

#apply the function to relevant columns
glioma_labels$Gender <- replace_missing(glioma_labels$Gender)
glioma_labels$Race <- replace_missing(glioma_labels$Race)
glioma_labels$Age_at_diagnosis <- replace_missing(glioma_labels$Age_at_diagnosis)

glioma_labels <- glioma_labels %>%
  mutate(
    #extract number of years and days (age) of patient
    years = as.numeric(str_extract(Age_at_diagnosis, "\\d+(?=\\s*years)")),
    days = as.numeric(str_extract(Age_at_diagnosis, "\\d+(?=\\s*days)")),
    
    #replace NA with 0 if one of the parts is missing
    years = ifelse(is.na(years), 0, years),
    days = ifelse(is.na(days), 0, days),
    
    #convert to decimal years
    Age_at_diagnosis = years + (days / 365)
  ) %>% 
  select(-years, -days)
```

```{r missing values}
#checking missing values

#impute Gender with mode
glioma_labels$Gender[is.na(glioma_labels$Gender)] <- names(sort(table(glioma_labels$Gender), decreasing = TRUE))[1]

#impute Race with mode
glioma_labels$Race[is.na(glioma_labels$Race)] <- names(sort(table(glioma_labels$Race), decreasing = TRUE))[1]

#convert Age_at_diagnosis to numeric
glioma_labels$Age_at_diagnosis <- as.numeric(glioma_labels$Age_at_diagnosis)

#impute Age_at_diagnosis with median
glioma_labels$Age_at_diagnosis[is.na(glioma_labels$Age_at_diagnosis)] <- median(glioma_labels$Age_at_diagnosis, na.rm = TRUE)

# Check for any remaining missing values
sum(is.na(glioma_labels$Gender))           
sum(is.na(glioma_labels$Race))             
sum(is.na(glioma_labels$Age_at_diagnosis)) 

```

```{r}
#processing to factorization and hotcoding

#hot coding mutation columns
mutation_cols <- colnames(glioma_labels)[8:27]

glioma_labels <- glioma_labels %>%
  mutate(across(all_of(mutation_cols),
                ~ ifelse(. == "MUTATED", 1,
                         ifelse(. == "NOT_MUTATED", 0, NA))),
         across(8:27, as.factor))

#turning hotcoded columns into factor cols
glioma_labels <- glioma_labels %>%
  select("Age_at_diagnosis", everything()) %>%
  mutate(across(2:24, as.factor))

head(glioma_labels)

```

```{r age/gender boxplot}
p <- ggplot(glioma_labels, mapping = aes(y = Age_at_diagnosis, x = Grade, 
                             fill = Gender)) +
  geom_boxplot() +
  scale_fill_manual(values = c("Male" = "#E84A27", "Female" = "#7393B3")) +
  labs(y = "Age at Diagnosis", title = "Diagnosis Type at Age & Gender Boxplot",
       fill = "Gender")  +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

p

#saving plot as png
ggsave("age_gender_diagnostics.png", plot = p, width = 6, height = 4, dpi = 300)
```



```{r race}
race_df <- glioma_labels
race_df$Race <- factor(glioma_labels$Race, levels = rev(levels(factor(glioma_labels$Race))))

race_plot <-  ggplot(race_df, aes(x = Race, fill = Race)) +
  geom_bar(position = 'dodge') + 
  labs(fill = "Race", y = "Count", title = "Proportion of Race within Patient Sample") +
  theme(axis.text.x = element_text(size = 6)) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  coord_flip() + 
  scale_fill_manual(values = uiuc_extended)

race_plot

#saving plot as png
ggsave("race_plot.png", plot = race_plot, width = 6, height = 2, dpi = 300)
```



```{r}
uiuc_org <- "#E84A27"
uiuc_blue <- "#4F6D94"
# Convert to long format
df_long <- glioma_labels %>%
  pivot_longer(cols = c(colnames(glioma_labels)[8:27]), 
               names_to = "Feature",
               values_to = "Value")

#grade across each Feature
grade_gene <- ggplot(df_long, aes(x = Value, fill = Grade)) +
  geom_bar(position = "stack") +
  facet_wrap(~ Feature, scales = "free_x") +
  labs(x = "Mutation Status (0 = Not Mutated, 1 = Mutated)", 
       y = "Count", 
       fill = "Grade",
       title = "Proportion of Classifications within Mutated Genes") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c('LGG' = uiuc_org, 'GBM' = uiuc_blue))

grade_gene

#saving plot as png
ggsave("grade_gene.png", plot = grade_gene, width = 6, height = 4, dpi = 300)
```



```{r multicollinearity}
model <- glm(Grade ~ ., data = glioma)

# Get VIF values
vif_values <- vif(model)

# Turn into a data frame for plotting
vif_df <- data.frame(
  Variable = names(vif_values),
  VIF = vif_values
)

vif_plot <- ggplot(vif_df, aes(x = reorder(Variable, VIF), y = VIF)) +
  geom_col(fill = uiuc_blue) +
  geom_hline(yintercept = 5, color = "red", linetype = "dashed") +  
  coord_flip() +
  labs(title = "VIF Values for Predictors", x = "Variables", y = "VIF") +
  theme_minimal()  +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        axis.text.y = element_text(size = 2))

vif_plot

#saving plot as png
ggsave("vif_plot.png", plot = vif_plot, width = 6, height = 2, dpi = 300)
```
```{r Splitting training and testing}
# set seed
set.seed(7)

#removing ID columns
glioma_Labels <- glioma_labels %>% 
  select(-Project, -Case_ID, -Primary_Diagnosis)

# number of rows in entire dataset
gliomaNumRows <- dim(glioma_Labels)[1]
gliomaTestNumRows <- gliomaNumRows*0.2

# separate dataset into train and test
test_idx <- sample(x = 1:gliomaNumRows, size = gliomaTestNumRows)
Glioma_train <- glioma_Labels[-test_idx,]
Glioma_test <- glioma_Labels[test_idx,]

#one-hot encoding
dummies <- dummyVars(Grade ~ ., data = glioma_Labels)

# apply transformation to train and test sets
X_train <- predict(dummies, newdata = Glioma_train)
X_test  <- predict(dummies, newdata = Glioma_test)

# extract labels
Y_train <- Glioma_train$Grade
Y_test  <- Glioma_test$Grade

```

##Finding optimal K for KNN

```{r KNN}
# parameters for cross-validation
resamplingMethod <- "cv"
numFolds <- 20
classificationMethod <- "knn"
performanceMetric <- "ROC"

# sequence of K values
K_seq <- data.frame(k = c(1, 5, 10, 20, 50, 100))

# setup the cross-validation options
knn_cv_train_control <- trainControl(method = resamplingMethod,
                                     number = numFolds,
                                     classProbs = TRUE,
                                     summaryFunction = twoClassSummary)

# train the model
knn_cv_train <- train(x = X_train,
                      y = Y_train,
                      method = classificationMethod,
                      metric = performanceMetric,
                      trControl = knn_cv_train_control,
                      tuneGrid = K_seq)

print(knn_cv_train)
```
### Fitting KNN model with optimal K
```{r KNN}
# best K
opt_K <- 10

knn_train <- knn(train = X_train,
                 test = X_test,
                 cl = Y_train,
                 k = opt_K, 
                 prob = TRUE)

### Extract probabilities (needed for AUC)
# Note: The 'prob' attribute gives the proportion of votes for the winning class
# For binary classification, we need probabilities for the positive class
knn_probs <- ifelse(
  knn_train == levels(Y_train)[2],  # Assuming 2nd level is the positive class
  attr(knn_train, "prob"),          # Probability of winning class
  1 - attr(knn_train, "prob")       # If predicted as negative, take 1 - prob
)

### Calculate AUC
roc_obj <- roc(response = Y_test, predictor = knn_probs)
auc_value <- auc(roc_obj)

### Print AUC
print(paste("AUC:", auc_value))

### Plot ROC curve (optional)
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))

# prediction confusion matrix on the test dataset
KNNconfusionMat <- table(Predicted = knn_train, Actual = Y_test)
print(KNNconfusionMat)
```
#### Calculating accuracy statistics
```{r KNN accuracy}
# calculate test error
numCorrectPredictions <- sum(diag(KNNconfusionMat))
numPredictions <- sum(KNNconfusionMat)
testError <- 1- (numCorrectPredictions/numPredictions)
print(paste0("The test error is: ", testError))

# calculate the sensitivity of each class
numClasses <- dim(KNNconfusionMat)[1]
for(i in 1:numClasses){
  # class label
  class_label_temp <- dimnames(KNNconfusionMat)$Actual[i]
  
  # calculate how many of the true occurrences of each class label were correctly classified
  num_predicted_class_label <- diag(KNNconfusionMat)[i]
  
  # calculate true number of occurrences of each class label
  num_true_class_label <- sum(KNNconfusionMat[,i])
  
  # calculate sensitivity
  sensitivity_temp <- num_predicted_class_label/num_true_class_label
  
  # print
  print(paste0("The sensitivity for class label ", class_label_temp, " is: ", sensitivity_temp))
}
```

###Logistic Regression

```{r Logistic Regression}

# Fit logistic regression (all predictors)
logistic_model <- glm(
  Grade ~ .,               
  data = Glioma_train,
  family = binomial(link = "logit")
)

# Model summary (check p-values)
summary(logistic_model)

#predict
pred_probs <- predict(logistic_model, newdata = Glioma_test, type = "response")

# Convert to class predictions (cutoff = 0.5)
pred_classes <- ifelse(pred_probs > 0.5, 1, 0)

# Confusion matrix
confusion_mat <- table(Predicted = pred_classes, Actual = Y_test)
print(confusion_mat)

# Metrics
accuracy <- sum(diag(confusion_mat)) / sum(confusion_mat)
sensitivity <- confusion_mat[2, 2] / sum(confusion_mat[, 2])  # TP / (TP + FN)
specificity <- confusion_mat[1, 1] / sum(confusion_mat[, 1])  # TN / (TN + FP)

cat("Accuracy:", round(accuracy, 3),
    "\nSensitivity:", round(sensitivity, 3),
    "\nSpecificity:", round(specificity, 3))

roc_obj <- roc(response = Y_test, predictor = pred_probs)
plot(roc_obj, main = "ROC Curve for Glioma Grade Prediction")
auc_value <- auc(roc_obj)
cat("AUC:", round(auc_value, 3))  # AUC > 0.7 indicates good discrimination

```


### Random Forest Classifier
```{r Random Forest Classifier}
library(randomForestSRC)
set.seed(7)
Glioma_RFC_auc <- rfsrc(Grade ~., data = as.data.frame(Glioma_train), ntree = 300, splitrule = "auc", importance = TRUE) 
#default value for mtry
#default value for nsplit = 0 because our dataset is not too large
Glioma_RFC_auc_predicted <- predict(Glioma_RFC_auc, newdata=Glioma_test)
Glioma_RFC_auc_predicted

```
```{r}
set.seed(7)
Glioma_RFC_gini <- rfsrc(Grade ~., data = as.data.frame(Glioma_train), ntree = 300, splitrule = "entropy", importance = TRUE) 

Glioma_RFC_gini_predicted <- predict(Glioma_RFC_gini, newdata=Glioma_test)
Glioma_RFC_gini_predicted
```
Using splitrule "auc", we achieve a lower test error.

### Gradient Boosting Model
```{r}
library(pROC)
#gbm requires output class to be {0,1}
Glioma_train_boosting <- Glioma_train %>% 
  mutate(Grade = ifelse(Grade=="GBM",1,0))
```

```{r}
library(gbm)
set.seed(7)

#Trying different learning rates (0.1, 0.01, 0.001) and using cv to choose optimal ntrees

# Learning Rate 0.1
Glioma_GBM1 <- gbm(Grade ~., data=Glioma_train_boosting, distribution="bernoulli", n.trees=1000, interaction.depth = 3, shrinkage=0.1, cv.folds = 5)
#finding optimal number of trees
best_iter1 <- gbm.perf(Glioma_GBM1, method = "cv")
#getting class labels
Glioma_GBM1_pred <- predict(Glioma_GBM1, newdata = Glioma_test, n.trees = best_iter1, type="response")
#converting reponse variable back into string for conf matrix
Glioma_GBM1_predicted <- ifelse(Glioma_GBM1_pred > 0.5, 1, 0)
Glioma_GBM1_predicted <- ifelse(Glioma_GBM1_predicted == 1, "GBM", "LGG")

Glioma_GBM1_conf_matrix <- table(Predicted = Glioma_GBM1_predicted, Actual = Glioma_test$Grade)
Glioma_GBM1_conf_matrix

Glioma_GBM1_test_error <- 1-(sum(diag(Glioma_GBM1_conf_matrix))/sum(Glioma_GBM1_conf_matrix))
Glioma_GBM1_test_error

 
auc_value <- auc(roc(Glioma_test$Grade, Glioma_GBM1_pred))
print(auc_value)
```
```{r}
set.seed(7)
# Learning Rate 0.01
Glioma_GBM2 <- gbm(Grade ~., data=Glioma_train_boosting, distribution="bernoulli", n.trees=3000, interaction.depth = 3, shrinkage=0.01, cv.folds = 5)
best_iter2 <- gbm.perf(Glioma_GBM2, method = "cv")

Glioma_GBM2_pred <- predict(Glioma_GBM2, newdata = Glioma_test, n.trees = best_iter2, type="response")
Glioma_GBM2_predicted <- ifelse(Glioma_GBM2_pred > 0.5, 1, 0)
Glioma_GBM2_predicted <- ifelse(Glioma_GBM2_predicted == 1, "GBM", "LGG")

Glioma_GBM2_conf_matrix <- table(Predicted = Glioma_GBM2_predicted, Actual = Glioma_test$Grade)
Glioma_GBM2_conf_matrix

Glioma_GBM2_test_error <- 1-(sum(diag(Glioma_GBM2_conf_matrix))/sum(Glioma_GBM2_conf_matrix))
Glioma_GBM2_test_error

auc_value <- auc(roc(Glioma_test$Grade, Glioma_GBM2_pred))
print(auc_value)
```

Glioma_GBM2 was our best gbm model 

### Adaboost

```{r}
set.seed(7)
# Learning Rate 0.01
Glioma_Ada <- gbm(Grade ~., data=Glioma_train_boosting, distribution="adaboost", n.trees=3000, interaction.depth = 3, shrinkage=0.01 ,cv.folds = 5)
best_iter_ada <- gbm.perf(Glioma_Ada, method = "cv")

Glioma_Ada_pred <- predict(Glioma_Ada, newdata = Glioma_test, n.trees = best_iter2, type="response")
Glioma_Ada_predicted <- ifelse(Glioma_Ada_pred > 0.5, 1, 0)
Glioma_Ada_predicted <- ifelse(Glioma_Ada_predicted == 1, "GBM", "LGG")

Glioma_Ada_conf_matrix <- table(Predicted = Glioma_Ada_predicted, Actual = Glioma_test$Grade)
Glioma_Ada_conf_matrix

Glioma_Ada_test_error <- 1-(sum(diag(Glioma_Ada_conf_matrix))/sum(Glioma_Ada_conf_matrix))
Glioma_Ada_test_error

auc_value <- auc(roc(Glioma_test$Grade, Glioma_Ada_pred))
print(auc_value)
```
Adaboost performed very similarly to GBM. Slightly higher test error but also higher AUC.


### SVM
```{r}
set.seed(7)
library(e1071)
tune_linear=tune(svm, Grade~., data=Glioma_train, kernel ="linear",
ranges=list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100), probability = TRUE)
)
summary(tune_linear)
```
```{r}
#Fitting SVM Model linear
Glioma_SVM_linear <- tune_linear$best.model

Glioma_SVM_linear_pred <- predict(Glioma_SVM_linear, Glioma_test, probability = TRUE) #returns labels directly
#getting probabilities to calculate AUC
Glioma_SVM_linear_probs <- attr(Glioma_SVM_linear_pred, "probabilities")



Glioma_SVM_linear_conf_matrix <- table(Predicted = Glioma_SVM_linear_pred, Actual = Glioma_test$Grade)
Glioma_SVM_linear_conf_matrix

Glioma_SVM_linear_test_error <- 1-(sum(diag(Glioma_SVM_linear_conf_matrix))/sum(Glioma_SVM_linear_conf_matrix))
Glioma_SVM_linear_test_error

auc_value <- auc(roc(Glioma_test$Grade, Glioma_SVM_linear_probs[,"GBM"]))
print(auc_value)
```


```{r}
set.seed(7)
tune_radial=tune(svm, Grade~., data=Glioma_train, kernel ="radial",
ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100)), probability = TRUE
)
Glioma_SVM_radial <- tune_radial$best.model

Glioma_SVM_radial_pred <- predict(Glioma_SVM_radial, Glioma_test, probability = TRUE) #returns labels directly
Glioma_SVM_radial_probs <- attr(Glioma_SVM_radial_pred, "probabilities")

Glioma_SVM_radial_conf_matrix <- table(Predicted = Glioma_SVM_radial_pred, Actual = Glioma_test$Grade)
Glioma_SVM_radial_conf_matrix

Glioma_SVM_radial_test_error <- 1-(sum(diag(Glioma_SVM_radial_conf_matrix))/sum(Glioma_SVM_radial_conf_matrix))
Glioma_SVM_radial_test_error

auc_value <- auc(roc(Glioma_test$Grade, Glioma_SVM_radial_probs[,"GBM"]))
print(auc_value)
```

```{r}
set.seed(7)
tune_poly=tune(svm, Grade~., data=Glioma_train, kernel ="polynomial",
ranges=list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100), degree=c(2,3)), probability = TRUE
)
Glioma_SVM_poly <- tune_poly$best.model

Glioma_SVM_poly_pred <- predict(Glioma_SVM_poly, Glioma_test, probability = TRUE) #returns labels directly
Glioma_SVM_poly_probs <- attr(Glioma_SVM_poly_pred, "probabilities")

Glioma_SVM_poly_conf_matrix <- table(Predicted = Glioma_SVM_poly_pred, Actual = Glioma_test$Grade)
Glioma_SVM_poly_conf_matrix

Glioma_SVM_poly_test_error <- 1-(sum(diag(Glioma_SVM_poly_conf_matrix))/sum(Glioma_SVM_poly_conf_matrix))
Glioma_SVM_poly_test_error

auc_value <- auc(roc(Glioma_test$Grade, Glioma_SVM_poly_probs[,"GBM"]))
print(auc_value)
```
All three SVM models performed similarly in terms of test error. The radial SVM model has the highest AUC among all our models.

